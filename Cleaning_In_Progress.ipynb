{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63cdb57d-b9e3-4aa4-b78d-f94be18165ab",
   "metadata": {},
   "source": [
    "Import all relevant functions. There are in total five categories of packages to import:\n",
    "\n",
    "1. Packages for preprocessing texts. E.g., to split earnings call text data into presentation and Q&A part, removal of direct identifiers, etc. This part is still a bit shaky and may need more general-purpose tools.\n",
    "2. Packages for named entity recognition. Here, SpaCy will do the job, spacy-llm is worth a try but needs careful pre-training so low in priority.\n",
    "3. Packages for generating text embeddings and calling LLMs for predictive checks. Here, LLamaIndex will encompass all the tools needed.\n",
    "4. The package spheroids for clustering on the embedding-space (which is on a *d*-dimensional sphere.\n",
    "5. Other packages for computational efficiency gain like panda-parallell, could be replaced with other stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f651f43-cbbf-4d61-a3b7-7e9a9291374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wucloud/.local/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Category 1, Spacy is technically category 3 but we already use it for preprocessing\n",
    "import os # for file reading\n",
    "import glob # for the same purpose\n",
    "import io # for temporal file writing when separating the earnings call\n",
    "import re # lots of regex stuff for preprocessing\n",
    "# For detecting executive names which we remove for being direct identifiers\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "# removal of names based on fuzzy matching, may require some hyperparameter tuning \n",
    "from fuzzywuzzy import fuzz\n",
    "# to turn company names into standard format for fuzzy matching based removal\n",
    "from cleanco import basename\n",
    "# packages to read and write pdf, the canvas soultion is not clean, CHANGE NEEDED IN FUTURE\n",
    "from pypdf import PdfReader,PdfWriter\n",
    "from pypdf.errors import PdfStreamError\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cb5a99-ea31-44b1-9f6f-f3a5dfdd1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteNewPdf(file,folder):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    try:\n",
    "        reader = PdfReader(file)\n",
    "    except PdfStreamError:\n",
    "        None\n",
    "    outputfile = PdfWriter()\n",
    "    firstpage = reader.pages[0].extract_text()\n",
    "    try:\n",
    "        ticker = re.search(r'(NYSE|NasdaqGS|XTRA|BATS|ASX|NasdaqGM|TSX):([A-Z\\.]+)', firstpage).group(2)\n",
    "    except AttributeError:\n",
    "        print('Ticker ' + ticker +' not found')\n",
    "        None\n",
    "    flag_presstart = False\n",
    "    flag_edwards = False #it has not Question and Answer header\n",
    "    writefilename = ticker + '.pdf'\n",
    "    if writefilename in [x for x in os.listdir(folder)]:\n",
    "        writefilename = writefilename.split('.')[0] + '_new.pdf'\n",
    "    for page_id, page in enumerate(reader.pages):\n",
    "        pagetxt = page.extract_text()\n",
    "        if bool(re.search(r'Table of Contents', pagetxt)):\n",
    "            if not bool(re.search(r'Presentation', pagetxt)):\n",
    "                print('No Presentation found on file:' + str(file))\n",
    "                break\n",
    "        elif bool(re.search(r'Call Participants', pagetxt)):\n",
    "            # extract Exec names\n",
    "            r = re.compile(r'[Tt][Hh][Ee]\\s')\n",
    "            r2 = re.compile(r'(International)|(Materials)')\n",
    "            companyname = r.sub('',basename(re.search(r'\\n(.*)[\\n]*(NYSE|NasdaqGS|XTRA|BATS|ASX|NasdaqGM|TSX)',\n",
    "                                                          firstpage).group(1)))\n",
    "                                \n",
    "            flag_edwards = bool(re.search(r'Edwards',firstpage))\n",
    "\n",
    "            #str(nlp(pagetxt).ents[0]).split(' FQ')[0] #first entry of the Call participants page is company name\n",
    "            if (companyname.isupper()) or (len(companyname.split())==1):\n",
    "                companyname_abbrv = companyname\n",
    "            else:\n",
    "                companyname_abbrv = ''.join([i[0] for i in companyname.split()])\n",
    "            # remove Middle names like Jim T. Johnes -> Jim Johnes\n",
    "            execnames = [re.sub(r'[A-Z]\\.','',str(e.text)) for e in nlp(pagetxt.split('ANALYSTS')[0]).ents if e.label_ =='PERSON']\n",
    "        else:\n",
    "            if bool(re.search(r'Presentation', pagetxt)):\n",
    "                flag_presstart = True\n",
    "            if flag_presstart:\n",
    "                # when reaching QA page finish\n",
    "                if bool(re.search(r'Question and Answer\\n', pagetxt)):\n",
    "                    break\n",
    "                if flag_edwards:\n",
    "                    if page_id == 8:\n",
    "                        break\n",
    "                doc = nlp(pagetxt)\n",
    "                for execid, execname in enumerate(execnames):\n",
    "                    matchednames = sorted(list(set([str(e.text) for e in doc.ents \\\n",
    "                     if (fuzz.partial_ratio(execname.lower(),str(e.text).lower())>=70) and e.label_ =='PERSON'])),\n",
    "                                          reverse=True)\n",
    "                    # sorted(,reverse=T) so that we first remove names like Jim Johnes and then remove Jim\n",
    "                    for matchedname in matchednames:\n",
    "                        pagetxt = pagetxt.replace(matchedname, '[Executive' + str(execid)+']')\n",
    "                #for comnameid, comname in enumerate([companyname,companyname_abbrv]):\n",
    "                matchedcomnames = sorted(list(set([str(e.text).split(' FQ')[0] for e in doc.ents\\\n",
    "                     if fuzz.partial_ratio(companyname.lower(),str(e.text).lower())>=70])),\n",
    "                                         reverse=True)\n",
    "                # handling some exceptions e.g., EPS for Pepsi\n",
    "                if 'EPS' in matchedcomnames:\n",
    "                    matchedcomnames.remove('EPS')\n",
    "                #print(matchedcomnames, companyname)\n",
    "                for matchedcomname in matchedcomnames:\n",
    "                    pagetxt = pagetxt.replace(matchedcomname,'[Company Name]')\n",
    "                matchedcomnames_abbrv = set([str(e.text).split(' FQ')[0] for e in doc.ents\\\n",
    "                     if fuzz.partial_ratio(companyname_abbrv,str(e.text))>70])\n",
    "                #print(matchedcomnames_abbrv, companyname_abbrv)\n",
    "                for matchedcomnames_abbrv in matchedcomnames_abbrv:\n",
    "                    pagetxt = pagetxt.replace(matchedcomnames_abbrv,'[Company Name]')\n",
    "                ent_urls = [str(e.text) for e in doc if e.like_url]\n",
    "                for ent_url in ent_urls:\n",
    "                    pagetxt = pagetxt.replace(ent_url,'[URL]')\n",
    "                packet = io.BytesIO()\n",
    "                can = canvas.Canvas(packet, pagesize = letter)\n",
    "                can.drawString(10,100,\n",
    "                               re.split(r'marketintelligence \\d+',\n",
    "                                       pagetxt)[-1].replace('\\n',' '))\n",
    "                can.save()\n",
    "                packet.seek(0)\n",
    "                new_pdf = PdfReader(packet)\n",
    "                outputfile.add_page(new_pdf.pages[0])          \n",
    "        outputfile.write(os.path.join(folder,writefilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56f030-3ec0-4b4a-91fd-4a3e6eaa6d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
